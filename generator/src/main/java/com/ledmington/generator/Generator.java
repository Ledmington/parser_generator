/*
 * parser-gen - Parser Generator
 * Copyright (C) 2025-2025 Filippo Barbari <filippo.barbari@gmail.com>
 *
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program.  If not, see <http://www.gnu.org/licenses/>.
 */
package com.ledmington.generator;

import java.util.ArrayDeque;
import java.util.ArrayList;
import java.util.Comparator;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;
import java.util.Optional;
import java.util.Queue;
import java.util.Set;
import java.util.function.Function;
import java.util.function.Supplier;
import java.util.stream.Collectors;

import com.ledmington.ebnf.Alternation;
import com.ledmington.ebnf.Expression;
import com.ledmington.ebnf.Grammar;
import com.ledmington.ebnf.Node;
import com.ledmington.ebnf.NonTerminal;
import com.ledmington.ebnf.OptionalNode;
import com.ledmington.ebnf.Production;
import com.ledmington.ebnf.Repetition;
import com.ledmington.ebnf.Sequence;
import com.ledmington.ebnf.Terminal;
import com.ledmington.ebnf.Utils;
import com.ledmington.generator.automata.AcceptingState;
import com.ledmington.generator.automata.AutomataUtils;
import com.ledmington.generator.automata.Automaton;
import com.ledmington.generator.automata.State;
import com.ledmington.generator.automata.StateTransition;

/** Generates Java code to parse a specified EBNF grammar. */
@SuppressWarnings("PMD.AvoidDuplicateLiterals")
public final class Generator {

	private static final Map<Node, String> NODE_NAMES = new HashMap<>();

	private Generator() {}

	/**
	 * Generates a String containing Java source code to parse the given EBNF grammar.
	 *
	 * @param root The root of the Node tree representing the structure of the EBNF grammar.
	 * @param parserName The name of the parser class produced.
	 * @param packageName The name of the package to output.
	 * @param startSymbol The name of the symbol to start matching from.
	 * @param indent The level of indentation to use when generating source code.
	 * @param generateMainMethod True to generate a self-contained executable parser which prints the resulting match.
	 * @return The indented Java source code of the parser of the given EBNF grammar.
	 */
	public static String generate(
			final Node root,
			final String parserName,
			final String packageName,
			final String startSymbol,
			final String indent,
			final boolean generateMainMethod) {
		NODE_NAMES.clear();

		final List<Production> lexerProductions = new ArrayList<>();
		final List<Production> parserProductions = new ArrayList<>();
		splitProductions((Grammar) root, startSymbol, lexerProductions, parserProductions);

		generateNames(parserProductions);

		final boolean atLeastOneOptional = NODE_NAMES.keySet().stream().anyMatch(n -> n instanceof OptionalNode);
		final boolean atLeastOneSequence = NODE_NAMES.keySet().stream().anyMatch(n -> n instanceof Sequence);
		final boolean atLeastOneRepetition = NODE_NAMES.keySet().stream().anyMatch(n -> n instanceof Repetition);
		final boolean atLeastOneAlternation = NODE_NAMES.keySet().stream().anyMatch(n -> n instanceof Alternation);

		final IndentedStringBuilder sb = new IndentedStringBuilder(indent);
		sb.append("/*\n")
				.append(" * This file has been generated by the parser generator. Do not edit.\n")
				.append(" */\n");
		if (packageName != null && !packageName.isBlank()) {
			sb.append("package ").append(packageName).append(";\n\n");
		}
		sb.append("import java.util.List;\n").append("import java.util.ArrayList;\n");
		if (atLeastOneSequence) {
			sb.append("import java.util.Stack;\n");
		}
		sb.append("import java.util.Map;\n")
				.append("import java.util.Objects;\n")
				.append("import java.util.Arrays;\n")
				.append("import java.util.function.Function;\n");
		if (generateMainMethod) {
			sb.append("import java.io.IOException;\n")
					.append("import java.nio.file.Files;\n")
					.append("import java.nio.file.Path;\n");
		}
		if (atLeastOneSequence || atLeastOneRepetition || generateMainMethod) {
			sb.append('\n');
		}
		sb.append("public final class ")
				.append(parserName)
				.append(" {\n")
				.indent()
				.append("private Token[] v = null;\n")
				.append("private int pos = 0;\n");
		if (atLeastOneSequence) {
			sb.append("private final Stack<Integer> stack = new Stack<>();\n");
		}
		sb.append("public interface Node {}\n").append("public record Terminal(String literal) implements Node {}\n");
		if (atLeastOneOptional) {
			sb.append("public record OptionalNode(Node inner) implements Node {}\n");
		}
		if (atLeastOneSequence) {
			sb.append("public record Sequence(List<Node> nodes) implements Node {}\n");
		}
		if (atLeastOneRepetition) {
			sb.append("public record Repetition(List<Node> nodes) implements Node {}\n");
		}
		if (atLeastOneAlternation) {
			sb.append("public record Alternation(Node inner) implements Node {}\n");
		}

		final String lexerName = parserName + "_Lexer";

		generateLexer(sb, lexerName, lexerProductions);

		sb.append("public Node parse(final String input) {\n").indent().append("final Node result;\n");

		sb.append("final ")
				.append(lexerName)
				.append(" lexer = new ")
				.append(lexerName)
				.append("();\n")
				.append("try {\n")
				.indent()
				.append("this.v = lexer.tokenize(input).toArray(new Token[0]);\n")
				.deindent()
				.append("} catch (final IllegalArgumentException e) {\n")
				.indent()
				.append("return null;\n")
				.deindent()
				.append("}\n")
				.append("this.pos = 0;\n")
				.append("try {\n")
				.indent();

		if (lexerProductions.stream().anyMatch(p -> p.start().name().equals(startSymbol))) {
			sb.append("result = parseTerminal(TokenType." + startSymbol + ");\n");
		} else {
			sb.append("result = parse_" + startSymbol + "();\n");
		}

		sb.deindent()
				.append("} catch (final ArrayIndexOutOfBoundsException e) {\n")
				.indent()
				.append("return null;\n")
				.deindent()
				.append("}\n");
		if (atLeastOneSequence) {
			sb.append("return (pos == v.length && stack.isEmpty()) ? result : null;\n");
		} else {
			sb.append("return pos == v.length ? result : null;\n");
		}
		sb.deindent().append("}\n");

		final Set<String> tokenNames = lexerProductions.stream()
				.map(p -> p.start().name().replace(' ', '_'))
				.collect(Collectors.toUnmodifiableSet());

		final Queue<Node> q = new ArrayDeque<>();
		final Set<Node> visited = new HashSet<>();

		for (final Production p : parserProductions) {
			generateNonTerminal(q, sb, p.start(), p.result(), tokenNames);
		}

		while (!q.isEmpty()) {
			final Node n = q.remove();
			if (visited.contains(n)) {
				continue;
			}
			visited.add(n);
			switch (n) {
				case OptionalNode opt -> generateOptionalNode(q, sb, NODE_NAMES.get(opt), opt, tokenNames);
				case NonTerminal ignored -> {
					// No need to generate anything here because we already handle non-terminals when visiting
					// the grammar's productions
				}
				case Sequence c -> generateSequence(q, sb, NODE_NAMES.get(c), c, tokenNames);
				case Repetition r -> generateRepetition(q, sb, NODE_NAMES.get(r), r, tokenNames);
				case Alternation a -> generateAlternation(q, sb, NODE_NAMES.get(a), a, tokenNames);
				default -> throw new IllegalArgumentException(String.format("Unknown node '%s'.", n));
			}
		}

		sb.append("private Terminal parseTerminal(final TokenType expected) {\n")
				.indent()
				.append("if (pos < v.length && v[pos].type() == expected) {\n")
				.indent()
				.append("return new Terminal(v[pos++].content());\n")
				.deindent()
				.append("}\n")
				.append("return null;\n")
				.deindent()
				.append("}\n");

		if (generateMainMethod) {
			sb.append("public static void main(final String[] args) {\n")
					.indent()
					.append("if (args.length != 1) {\n")
					.indent()
					.append("throw new RuntimeException(\"Expected the file to read input from.\");\n")
					.deindent()
					.append("}\n")
					.append("final ")
					.append(parserName)
					.append(" parser = new ")
					.append(parserName)
					.append("();\n")
					.append("try {\n")
					.indent()
					.append("System.out.println(parser.parse(Files.readString(Path.of(args[0]))));\n")
					.deindent()
					.append("} catch (final IOException e) {\n")
					.indent()
					.append("throw new RuntimeException(e);\n")
					.deindent()
					.append("}\n")
					.deindent()
					.append("}\n");
		}

		return sb.deindent().append("}").toString();
	}

	private static void splitProductions(
			final Grammar g,
			final String startSymbol,
			final List<Production> lexerProductions,
			final List<Production> parserProductions) {
		// Divide all trivial lexer productions from the rest
		for (final Production p : g.productions()) {
			if (p.isLexerProduction()) {
				lexerProductions.add(p);
			} else {
				parserProductions.add(p);
			}
		}

		// Convert all terminal symbols still in the parser into "anonymous" non-terminal ones
		final Supplier<String> name = new Supplier<>() {
			private int id = 0;

			@Override
			public String get() {
				return "terminal_" + (id++);
			}
		};
		for (int i = 0; i < parserProductions.size(); i++) {
			final Production p = parserProductions.get(i);
			if (containsAtLeastOneTerminal(p.result())) {
				parserProductions.set(
						i, new Production(p.start(), convertExpression(name, lexerProductions, p.result())));
			}
		}

		// Final sort by name the productions
		lexerProductions.sort(Comparator.comparing(a -> a.start().name()));
		parserProductions.sort(Comparator.comparing(a -> a.start().name()));
	}

	private static Expression convertExpression(
			final Supplier<String> name, final List<Production> lexerProductions, final Expression e) {
		return switch (e) {
			case Terminal t -> {
				final Optional<Production> replacement = lexerProductions.stream()
						.filter(p -> p.result() instanceof Terminal(final String literal)
								&& t.literal().equals(literal))
						.findFirst();
				// Avoid generating fake non-terminal nodes for terminals already present in other productions
				if (replacement.isPresent()) {
					yield replacement.orElseThrow().start();
				} else {
					final String newName = name.get();
					final NonTerminal nt = new NonTerminal(newName);
					lexerProductions.add(new Production(nt, t));
					NODE_NAMES.put(nt, newName);
					yield nt;
				}
			}
			case NonTerminal nt -> nt;
			case OptionalNode o -> new OptionalNode(convertExpression(name, lexerProductions, o.inner()));
			case Repetition r -> new Repetition(convertExpression(name, lexerProductions, r.inner()));
			case Sequence s ->
				new Sequence(s.nodes().stream()
						.map(n -> convertExpression(name, lexerProductions, n))
						.toList());
			case Alternation a ->
				new Alternation(a.nodes().stream()
						.map(n -> convertExpression(name, lexerProductions, n))
						.toList());
			default -> throw new IllegalArgumentException(String.format("Unknown node '%s'.", e));
		};
	}

	private static boolean containsAtLeastOneTerminal(final Node n) {
		return switch (n) {
			case Terminal ignored -> true;
			case NonTerminal ignored -> false;
			case OptionalNode o -> containsAtLeastOneTerminal(o.inner());
			case Repetition r -> containsAtLeastOneTerminal(r.inner());
			case Sequence s -> s.nodes().stream().anyMatch(Generator::containsAtLeastOneTerminal);
			case Alternation a -> a.nodes().stream().anyMatch(Generator::containsAtLeastOneTerminal);
			default -> throw new IllegalArgumentException(String.format("Unknown node '%s'.", n));
		};
	}

	private static void generateLexer(
			final IndentedStringBuilder sb, final String lexerName, final List<Production> lexerProductions) {
		final Automaton epsilonNFA = AutomataUtils.grammarToEpsilonNFA(lexerProductions);
		// System.out.println(epsilonNFA.toGraphviz());
		AutomataUtils.assertEpsilonNFAValid(epsilonNFA);
		final Automaton nfa = AutomataUtils.epsilonNFAtoNFA(epsilonNFA);
		// System.out.println(nfa.toGraphviz());
		AutomataUtils.assertNFAValid(nfa);
		final Automaton dfa = AutomataUtils.NFAtoDFA(nfa);
		// System.out.println(dfa.toGraphviz());
		AutomataUtils.assertDFAValid(dfa);
		final Automaton minimizedDFA = AutomataUtils.minimizeDFA(dfa);
		// System.out.println(minimizedDFA.toGraphviz());
		AutomataUtils.assertDFAValid(minimizedDFA);

		// re-index DFA states
		final Map<State, Integer> stateIndex = new HashMap<>();
		stateIndex.put(minimizedDFA.startingState(), 0);
		int idx = 1;
		for (final State s : minimizedDFA.states()) {
			if (s.equals(minimizedDFA.startingState())) {
				continue;
			}
			stateIndex.put(s, idx);
			idx++;
		}

		final List<State> allStates = stateIndex.entrySet().stream()
				.sorted(Entry.comparingByValue())
				.map(Entry::getKey)
				.toList();

		sb.append("public enum TokenType {\n")
				.indent()
				.append(lexerProductions.stream()
						.map(p -> p.start().name().replace(' ', '_'))
						.sorted()
						.collect(Collectors.joining(",\n")))
				.append('\n')
				.deindent()
				.append("}\n");
		sb.append("public record Token(TokenType type, String content) {\n")
				.indent()
				.append("public Token {\n")
				.indent()
				.append("Objects.requireNonNull(type);\n")
				.deindent()
				.append("}\n")
				.deindent()
				.append("}\n");

		sb.append("public final class ")
				.append(lexerName)
				.append(" {\n")
				.indent()
				.append("private char[] v = null;\n")
				.append("private int pos = 0;\n")
				.append("private Token lastTokenMatched = null;\n")
				.append("private int lastTokenMatchPosition = 0;\n");

		sb.append("private final boolean[] isAccepting = new boolean[] {");
		generateList(sb, allStates, s -> s.isAccepting() ? "true" : "false");
		sb.append("};\n");

		sb.append("private final List<Function<String, Token>> tokensToMatch = Arrays.asList(\n")
				.indent();
		for (int i = 0; i < allStates.size(); i++) {
			final State s = allStates.get(i);
			sb.append(
					s.isAccepting() ? "s -> new Token(TokenType." + ((AcceptingState) s).tokenName() + ", s)" : "null");
			if (i < allStates.size() - 1) {
				sb.append(',');
			}
			sb.append('\n');
		}
		sb.deindent().append(");\n");

		// TODO: change this into three arrays for better performance
		sb.append("private final Map<Integer, Map<Character, Integer>> transitions = Map.ofEntries(\n")
				.indent();
		for (int i = 0; i < allStates.size(); i++) {
			final int final_i = i;
			final List<StateTransition> transitions = minimizedDFA.transitions().stream()
					.filter(t -> t.from().equals(allStates.get(final_i)))
					.sorted(Comparator.comparing(StateTransition::character))
					.toList();
			sb.append("Map.entry(").append(i).append(", Map.ofEntries(");
			if (!transitions.isEmpty()) {
				sb.append('\n').indent();
				for (int j = 0; j < transitions.size(); j++) {
					final StateTransition t = transitions.get(j);
					if (t.from().equals(allStates.get(i))) {
						sb.append("Map.entry('")
								.append(Utils.getEscapeCharacter(t.character()))
								.append("', ")
								.append(stateIndex.get(t.to()))
								.append(")");
						if (j < transitions.size() - 1) {
							sb.append(',');
						}
						sb.append('\n');
					}
				}
				sb.deindent();
			}
			sb.append("))");
			if (i < allStates.size() - 1) {
				sb.append(',');
			}
			sb.append('\n');
		}
		sb.deindent().append(");\n");

		sb.append("public ")
				.append(lexerName)
				.append("() {}\n")
				.append("public List<Token> tokenize(final String input) {\n")
				.indent()
				.append("this.v = input.toCharArray();\n")
				.append("this.pos = 0;\n")
				.append("final List<Token> tokens = new ArrayList<>();\n")
				.append("int currentState = 0;\n")
				.append("this.lastTokenMatched = null;\n")
				.append("this.lastTokenMatchPosition = 0;\n")
				.append("while (this.pos < v.length) {\n")
				.indent()
				.append("if (isAccepting[currentState]) {\n")
				.indent()
				.append("if (lastTokenMatchPosition == pos) {\n")
				.indent()
				.append(
						"throw new IllegalArgumentException(String.format(\"No token emitted for empty match at index %,d.\", pos));\n")
				.deindent()
				.append("}\n")
				.append("final String match = input.substring(lastTokenMatchPosition, pos);\n")
				.append("lastTokenMatched = tokensToMatch.get(currentState).apply(match);\n")
				.append("lastTokenMatchPosition = pos;\n")
				.deindent()
				.append("}\n")
				.append("final char ch = v[pos];\n")
				.append("if (transitions.get(currentState).containsKey(ch)) {\n")
				.indent()
				.append("currentState = transitions.get(currentState).get(ch);\n")
				.append("pos++;\n")
				.deindent()
				.append("} else {\n")
				.indent()
				.append("if (lastTokenMatched != null) {\n")
				.indent()
				.append("tokens.add(lastTokenMatched);\n")
				.append("currentState = 0;\n")
				.append("lastTokenMatched = null;\n")
				.append("pos = lastTokenMatchPosition;\n")
				.deindent()
				.append("} else {\n")
				.indent()
				.append("throw new IllegalArgumentException(String.format(\"Lexical error at index %,d.\", pos));\n")
				.deindent()
				.append("}\n")
				.deindent()
				.append("}\n")
				.deindent()
				.append("}\n")
				.append("if (isAccepting[currentState]) {\n")
				.indent()
				.append("final String match = input.substring(lastTokenMatchPosition, pos);\n")
				.append("tokens.add(tokensToMatch.get(currentState).apply(match));\n")
				.append("return tokens;\n")
				.deindent()
				.append("} else {\n")
				.indent()
				.append("throw new IllegalArgumentException(\"Could not tokenize input.\");\n")
				.deindent()
				.append("}\n")
				.deindent()
				.append("}\n")
				.deindent()
				.append("}\n");
	}

	private static <X> void generateList(
			final IndentedStringBuilder sb, final List<X> elements, final Function<X, String> serializer) {
		if (elements.isEmpty()) {
			return;
		}
		sb.append(serializer.apply(elements.getFirst()));
		for (int i = 1; i < elements.size(); i++) {
			sb.append(", ").append(serializer.apply(elements.get(i)));
		}
	}

	private static void generateAlternation(
			final Queue<Node> q,
			final IndentedStringBuilder sb,
			final String productionName,
			final Alternation a,
			final Set<String> tokenNames) {
		sb.append("private Alternation parse_" + productionName + "() {\n").indent();
		final List<Expression> nodes = a.nodes();
		for (int i = 0; i < nodes.size(); i++) {
			final Node n = nodes.get(i);
			final String nodeName = "n_" + i;
			if (n instanceof NonTerminal(final String tokenName) && tokenNames.contains(tokenName)) {
				sb.append("final Node " + nodeName + " = parseTerminal(TokenType." + tokenName + ");\n");
			} else {
				sb.append("final Node " + nodeName + " = parse_" + NODE_NAMES.get(n) + "();\n");
				q.add(n);
			}
			sb.append("if (" + nodeName + " != null) {\n")
					.indent()
					.append("return new Alternation(" + nodeName + ");\n")
					.deindent()
					.append("}\n");
		}
		sb.append("return null;\n").deindent().append("}\n");
	}

	private static void generateRepetition(
			final Queue<Node> q,
			final IndentedStringBuilder sb,
			final String productionName,
			final Repetition r,
			final Set<String> tokenNames) {
		sb.append("private Repetition parse_" + productionName + "() {\n")
				.indent()
				.append("final List<Node> nodes = new ArrayList<>();\n")
				.append("while (true) {\n")
				.indent();
		if (r.inner() instanceof NonTerminal(final String tokenName) && tokenNames.contains(tokenName)) {
			sb.append("final Node n = parseTerminal(TokenType." + tokenName + ");\n");
		} else {
			sb.append("final Node n = parse_" + NODE_NAMES.get(r.inner()) + "();\n");
			q.add(r.inner());
		}
		if (!(r.inner() instanceof Repetition)) {
			sb.append("if (n == null) {\n")
					.indent()
					.append("break;\n")
					.deindent()
					.append("}\n");
		}
		sb.append("nodes.add(n);\n")
				.deindent()
				.append("}\n")
				.append("return new Repetition(nodes);\n")
				.deindent()
				.append("}\n");
	}

	private static void generateSequence(
			final Queue<Node> q,
			final IndentedStringBuilder sb,
			final String productionName,
			final Sequence s,
			final Set<String> tokenNames) {
		sb.append("private Sequence parse_" + productionName + "() {\n")
				.indent()
				.append("final List<Node> nodes = new ArrayList<>();\n")
				.append("stack.push(this.pos);\n");

		final List<Expression> seq = s.nodes();
		for (int i = 0; i < seq.size(); i++) {
			final Node n = seq.get(i);
			final String nodeName = "n_" + i;
			if (n instanceof NonTerminal(final String tokenName) && tokenNames.contains(tokenName)) {
				sb.append("final Node " + nodeName + " = parseTerminal(TokenType." + tokenName + ");\n");
			} else {
				sb.append("final Node " + nodeName + " = parse_" + NODE_NAMES.get(n) + "();\n");
				q.add(n);
			}
			if (!(n instanceof Repetition)) {
				sb.append("if (" + nodeName + " == null) {\n")
						.indent()
						.append("this.pos = stack.pop();\n")
						.append("return null;\n")
						.deindent()
						.append("}\n");
			}
			sb.append("nodes.add(" + nodeName + ");\n");
		}

		sb.append("stack.pop();\n")
				.append("return new Sequence(nodes);\n")
				.deindent()
				.append("}\n");
	}

	private static void generateNonTerminal(
			final Queue<Node> q,
			final IndentedStringBuilder sb,
			final NonTerminal start,
			final Expression result,
			final Set<String> tokenNames) {
		sb.append("private Node parse_")
				.append(NODE_NAMES.get(start))
				.append("() {\n")
				.indent();
		if (result instanceof NonTerminal(final String tokenName) && tokenNames.contains(tokenName)) {
			sb.append("return parseTerminal(TokenType." + tokenName + ");\n");
		} else {
			sb.append("return parse_" + NODE_NAMES.get(result) + "();\n");
			q.add(result);
		}
		sb.deindent().append("}\n");
	}

	private static void generateNames(final List<Production> parserProductions) {
		final Set<Node> visited = new HashSet<>();
		final Queue<Node> q = new ArrayDeque<>();

		for (final Production p : parserProductions) {
			q.add(p.start());
			q.add(p.result());
		}

		int optionalCounter = 0;
		int sequenceCounter = 0;
		int repetitionCounter = 0;
		int alternationCounter = 0;
		while (!q.isEmpty()) {
			final Node n = q.remove();
			if (visited.contains(n)) {
				continue;
			}
			visited.add(n);
			switch (n) {
				case Terminal ignored -> {}
				case NonTerminal nt -> NODE_NAMES.put(nt, nt.name().replace(' ', '_'));
				case OptionalNode opt -> {
					NODE_NAMES.put(opt, "optional_" + optionalCounter);
					q.add(opt.inner());
					optionalCounter++;
				}
				case Repetition r -> {
					NODE_NAMES.put(r, "repetition_" + repetitionCounter);
					repetitionCounter++;
					q.add(r.inner());
				}
				case Sequence s -> {
					NODE_NAMES.put(s, "sequence_" + sequenceCounter);
					sequenceCounter++;
					q.addAll(s.nodes());
				}
				case Alternation a -> {
					NODE_NAMES.put(a, "alternation_" + alternationCounter);
					alternationCounter++;
					q.addAll(a.nodes());
				}
				default -> throw new IllegalArgumentException(String.format("Unknown Node '%s'.", n));
			}
		}
	}

	private static void generateOptionalNode(
			final Queue<Node> q,
			final IndentedStringBuilder sb,
			final String productionName,
			final OptionalNode o,
			final Set<String> tokenNames) {
		sb.append("private OptionalNode parse_" + productionName + "() {\n").indent();
		if (o.inner() instanceof NonTerminal(final String tokenName) && tokenNames.contains(tokenName)) {
			sb.append("final Node inner = parseTerminal(TokenType." + tokenName + ");\n");
		} else {
			sb.append("final Node inner = parse_" + NODE_NAMES.get(o.inner()) + "();\n");
			q.add(o.inner());
		}
		sb.append("return new OptionalNode(inner);\n").deindent().append("}\n");
	}
}
